{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimate probability densities at all the points $p(x_i)$ in the sample by finding distances to the $k$ nearest neighbors of each $x_i$.\n",
    "- Average logarithm of these densities are found and adjusted by bias correction terms.\n",
    "\n",
    "## Conditional TE for point processes.\n",
    "\n",
    "Originally bivariate by Spinney.\n",
    "\n",
    "$$\n",
    "\\bf \\dot{T}_{Y \\to X} = \\lim_{t \\to \\infty} \\dfrac{1}{\\tau} \\sum_{i=1}^{N_X} \n",
    "\\log{\n",
    "    \\dfrac{\\lambda_{x | {\\bf x_{<t}}, {\\bf y_{<t}} } [{\\bf x_{<x_i}}, {\\bf y_{<x_i}}]}{\\lambda_{x | {\\bf x_{<t}}} [\\bf x_{<x_i>}]}\n",
    "}\n",
    "$$\n",
    "\n",
    "- $X$ and $Y$ are series of *time points* $x_i$ and $y_j$ of the events $i$ and $j$ in the target and source, respectively.\n",
    "- $N_X$ is the number of events in the target process.\n",
    "- $\\tau$ is the length in time of this process.\n",
    "- $\\lambda_{x | {\\bf x_{<t}}, {\\bf y_{<t}} } [{\\bf x_{<x_i}}, {\\bf y_{<x_i}}]$ is the instantaneous firing rate of the target, conditioned on the histories of the target $\\bf x_{<x_i}$ and source $\\bf y_{<x_i}$ at time points $x_i$ of the target process.\n",
    "- $[\\bf x_{<x_i>}]$ is the instantaneous firing rate of the target, conditioned on on its history alone.\n",
    "\n",
    "\n",
    "## Continuous-time TE as sum of differential entropies\n",
    "\n",
    "\n",
    "Assumptions:\n",
    "- $X \\in \\mathbb{R}^{N_X}$ and $Y \\in \\mathbb{R}^{N_X}$ are two point processes, where each element represents the time of an event. \n",
    "- The set of extra conditioning processes are $\\bf \\mathcal{Z} = \\{ Z_1, Z_2, \\ldots, Z_{n_\\mathcal{Z}} \\}$.\n",
    "- Define a *counting process* $\\bf N_X(t)$ on $X$.\n",
    "-  $N \\in \\mathbb{N}$ represents the 'state' of the process, incremented by one at the occurrence of an event.\n",
    "- The instantaneous firing rate is $$ \\lambda_X(t) = \\lim_{\\Delta t \\to 0} \\dfrac{p(\\bf N_X(T + \\Delta t) - \\bf N_{X}(t) = 1)}{\\Delta t}$$\n",
    "\n",
    "- Assume an unknown probability distribution $\\mu(\\bf x)$ with $\\bf x \\in \\mathbb{R}^d$.\n",
    "\n",
    "Instantaneous firing rate:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\bf \\dot{T}_{Y \\to X | \\mathcal{Z}} = \\bar{\\lambda}_X \\lim_{\\Delta t \\to 0} \\mathbb{E}_{P_X} \n",
    "\\left[\n",
    "    \\log{\n",
    "        \\dfrac{p_U(\\bf N_X(x + \\Delta t) - \\bf N_X(x) = 1 | \\bf x_{<x}, \\bf y_{<x}, \\bf \\mathcal{Z}_{<x}) }{p_U(\\bf N_X(x + \\Delta t) - \\bf{N}_X(x) = 1 | \\bf x_{<x}, \\bf \\mathcal{z}_{<x})}\n",
    "    }\n",
    "\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Code/Repos/Temp/TransferEntropy.jl`\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using Pkg;\n",
    "Pkg.activate(\"../\")\n",
    "#Pkg.free(\"DelayEmbeddings\")\n",
    "#Pkg.add(url = \"https://github.com/JuliaDynamics/DelayEmbeddings.jl\", \n",
    "#    rev = \"hcat_multiple_datasets\")\n",
    "#Pkg.add(url = \"https://github.com/JuliaDynamics/Entropies.jl\")\n",
    "\n",
    "using DelayEmbeddings, Entropies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "      Thrown: ErrorException"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using StaticArrays, DelayEmbeddings\n",
    "\n",
    "\"\"\"\n",
    "    EventIdentifier\n",
    "\n",
    "An abstract type indicating some sort of event.\n",
    "\"\"\"\n",
    "abstract type EventIdentifier end\n",
    "\n",
    "\"\"\"\n",
    "    OneSpike <: EventIdentifier\n",
    "    OneSpike()\n",
    "\n",
    "Events are indicated by the presence of `1`s or `true`s.\n",
    "\n",
    "## Example\n",
    "\n",
    "```julia\n",
    "# Events occur at indices 2, 4, and 6.\n",
    "x = [0, 1, 0, 1, 0, 1]\n",
    "\n",
    "# Events again occur at indices 2, 4, and 6.\n",
    "x = [-2, 1, 5, 1, 2, 1]\n",
    "```\n",
    "\"\"\"\n",
    "struct OneSpike <: EventIdentifier end\n",
    "\n",
    "\"\"\" \n",
    "    first_index(x::AbstractVector{T}, m::Int) where T\n",
    "\n",
    "Find the first time index for which a continuous-time embedding with history \n",
    "length `m` can be constructed.\n",
    "\"\"\"\n",
    "function first_index(x::AbstractVector{T}, event::EventIdentifier = OneSpike(); \n",
    "        m::Int = 2) where T\n",
    "\n",
    "    spike = one(T)\n",
    "\n",
    "    i::Int = 1\n",
    "    ct::Int = 0\n",
    "    while ct < m && i < length(y)\n",
    "        if x[i] == spike\n",
    "            ct += 1\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "\n",
    "    ct >= m || throw(ErrorException(\"Could not find m=$m spikes in `x`\"))\n",
    "\n",
    "    return i\n",
    "end\n",
    "\n",
    "function first_index(x::AbstractDataset{D, T}, event::EventIdentifier = OneSpike(); \n",
    "        m::Int = 2) where {D, T}\n",
    "    \n",
    "    spike = one(T)\n",
    "    L = length(x)\n",
    "    cts::MVector{D, Int} = zeros(MVector{D, Int})\n",
    "    \n",
    "    i::Int = 1\n",
    "    while any(cts .< m) && i < L\n",
    "        for d = 1:D\n",
    "            if x[i][d] == spike\n",
    "                cts[d] += 1\n",
    "            end\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "    \n",
    "    all(cts .>= m) || \n",
    "        throw(ErrorException(\"Couldn't find m=$m spikes in one or more columns of `x`\"))\n",
    "    return i\n",
    "end\n",
    "\n",
    "first_index(xs; kwargs...) = map(v -> first_index.(v; kwargs...), xs)\n",
    "\n",
    "using Test\n",
    "using DelayEmbeddings\n",
    "z = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
    "x = [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
    "y = [1, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
    "D = Dataset(x, y, z)\n",
    "@test first_index(z, m = 2) == 4\n",
    "@test first_index(z, m = 3) == 7\n",
    "@test first_index(z, m = 4) == 8\n",
    "@test first_index(D, m = 2) == 5\n",
    "@test first_index(D, m = 3) == 7\n",
    "@test_throws ErrorException first_index(D, m = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    spikeembed(i, iₜmin, x; spike = one(eltype(x)), m::Int = 2) where T <: Number\n",
    "\n",
    "Given scalar-valued `x`, and history length `m`, make a *continuous-time* embedding,\n",
    "by counting the duration between spikes relative to time index `iₜ`. \n",
    "\n",
    "`iₜmin` is the  minimum index for which to start checking, to ensure that a \n",
    "length-`m` embedding vector is actually possible to construct. This must have been \n",
    "checked beforehand by using [`first_index`](@ref), otherwise errors will be thrown.\n",
    "\n",
    "See Fig 10 in Shorten et al. (2021) for details.\n",
    "\n",
    "!!! note \"Availability of length-`m` embedding vectors\" \n",
    "    This function assumes that there are at least `m` spikes available before time index \n",
    "    `iₜ`. This function does not check for the existence of such spikes. Pre-check by using \n",
    "    [`first_index`](@ref). If no spikes exist to form an embedding, an error will be thrown.\n",
    "\n",
    "[^Shorten2021]: Shorten, D. P., Spinney, R. E., & Lizier, J. T. (2021). Estimating transfer\n",
    "    entropy in continuous time between neural spike trains or other event-based data. PLoS \n",
    "    computational biology, 17(4), e1008054.\n",
    "\"\"\"\n",
    "function spikeembed(target::AbstractVector{T}, event::EventIdentifier = OneSpike(); \n",
    "            m::Int = 2, # The same embedding for all timeseries processes for now.\n",
    "            ) where T\n",
    "    spike_identifier = one(T)\n",
    "\n",
    "    # We can't know a priori how many elements this vector will contain,\n",
    "    # because we're counting time *intervals* relative to some tᵢ, not \n",
    "    # *values at particular times relative to tᵢ*.\n",
    "    emb = Vector{SVector{m, T}}(undef, 0)\n",
    "    iₜmin = first_index(target; m)\n",
    "\n",
    "    # Pre-allocate single vector to avoid excessive allocations, and convert\n",
    "    # back to SVector inside the inner function. If the compiler is feeling fine, then \n",
    "    # this *could* incur no extra cost.\n",
    "    p = zeros(MVector{m, T})\n",
    "\n",
    "    L = length(target)\n",
    "    for iₜ in iₜmin:L\n",
    "        push!(emb, embed_at_iₜ_event!(p, iₜ, target, spike_identifier; m))\n",
    "    end\n",
    "    return emb\n",
    "end\n",
    "\n",
    "using BenchmarkTools\n",
    "\n",
    "# Embeddings vectiors constructed at *all* times (independent of target spiking events).\n",
    "function embed_at_alltimes(x::AbstractDataset{D, T}, event::EventIdentifier = OneSpike(); \n",
    "        m::Int = 2) where {D, T}\n",
    "    spike_identifier = one(T)\n",
    "\n",
    "    # Here, we don't care about the timing of spikes in the target time series, \n",
    "    # so construct embedding points for all possible time indices `iₜ`\n",
    "    iₜmin = first_index(x; m)\n",
    "    L = length(x)\n",
    "\n",
    "    # After finding the minimum required index for `m`-length history vectors to\n",
    "    # exist, we can also know the size of the embeddings.\n",
    "    embeddings = [Vector{SVector{m, Int}}(undef, (L - iₜmin + 1)) for d = 1:D]\n",
    "\n",
    "    # Pre-allocate single vector to avoid excessive allocations, and convert\n",
    "    # back to SVector inside the inner function. If the compiler is feeling fine, then \n",
    "    # this *could* incur no extra cost.\n",
    "    p = zeros(MVector{m, T})\n",
    "\n",
    "    for d = 1:D\n",
    "        ts = x[:, SVector{1, Int}(d)]\n",
    "        for (i, iₜ) in enumerate(iₜmin:L)\n",
    "            embeddings[d][i] = embed_at_iₜ_event!(p, iₜ, ts, spike_identifier; m)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return Dataset.(embeddings)\n",
    "end\n",
    "\n",
    "\n",
    "# Embeddings constructed only *at* target spikes.\n",
    "function embed_at_targetspikes(x::AbstractDataset{D, T}, event::EventIdentifier = OneSpike(); \n",
    "        m::Int = 2) where {D, T}\n",
    "    spike_identifier = one(T)\n",
    "\n",
    "    # Spikes in the *target* time series control which time indices for which\n",
    "    # we construct embeddings.\n",
    "    target = x[:, 1]\n",
    "    inds_spikes = findall(target .== spike_identifier)\n",
    "\n",
    "    # Ensure that all time series have enough spikes to be embedded.\n",
    "    iₜmin = first_index(x; m)\n",
    "    inds_spikes_valid = inds_spikes[inds_spikes .> iₜmin]\n",
    "    L = length(inds_spikes_valid)\n",
    "    \n",
    "    # After finding the minimum required index for `m`-length history vectors to\n",
    "    # exist, we can also know the size of the embeddings.\n",
    "    embeddings = [Vector{SVector{m, Int}}(undef, L) for d = 1:D]\n",
    "\n",
    "    # Pre-allocate single vector to avoid excessive allocations, and convert\n",
    "    # back to SVector inside the inner function. If the compiler is feeling fine, then \n",
    "    # this *could* incur no extra cost.\n",
    "    p = zeros(MVector{m, T})\n",
    "\n",
    "    for d in 1:D\n",
    "        ts = x[:, SVector{1, Int}(d)]\n",
    "        for (i, iₜ) in enumerate(inds_spikes_valid)\n",
    "            embeddings[d][i] = embed_at_iₜ_event!(p, iₜ, ts, spike_identifier; m)\n",
    "        end\n",
    "    end\n",
    "    return Dataset.(embeddings)\n",
    "end\n",
    "\n",
    "function spike_embeddings(x::AbstractDataset{D, T}, event::EventIdentifier = OneSpike(); \n",
    "        m::Int = 2) where {D, T}\n",
    "    Eₜ = embed_at_targetspikes(x, event; m)\n",
    "    Eᵤ = embed_at_alltimes(x, event; m)\n",
    "    if D <= 2\n",
    "        vars_cond = 1:2\n",
    "    else\n",
    "        vars_cond = [1; 3:length(Eₜ)]\n",
    "    end\n",
    "    # Joint embedding vector sets J include all variables, while conditional embedding sets\n",
    "    # vector sets C excludes the source variable, which is assumed to always be \n",
    "    # in position 2.\n",
    "    Jₓ = hcat(Eₜ...)\n",
    "    Cₓ = hcat(Eₜ[vars_cond]...)\n",
    "    Jᵤ = hcat(Eᵤ...)\n",
    "    Cᵤ = hcat(Eᵤ[vars_cond]...)\n",
    "\n",
    "    return Jₓ, Cₓ, Jᵤ, Cᵤ\n",
    "end\n",
    "\n",
    "# Given a time index iₜ, find the `m` first intra-spike time intervals between\n",
    "# t = t(iₜ) and t = t(1). Store the result in the pre-allocated MVector `v`.\n",
    "# Spikes are identified using `spike_identifier` (usually `1`), but can\n",
    "# be any identifier. Assumes `x` is a view of the [1:iₜ] first elements of x (Vector{StaticVector}).\n",
    "function embed_at_iₜ_event!(v, iₜ, x, event_identifier; m = 2)\n",
    "    n_found::Int = 0 # The number of embedding entries found.\n",
    "    n_checked::Int = 0 # How many checked since last spike was found?\n",
    "    k::Int = iₜ\n",
    "    \n",
    "    @inbounds while n_found < m\n",
    "        if x[k - 1][] == event_identifier\n",
    "            n_found += 1\n",
    "            v[n_found] = n_checked\n",
    "            n_checked = 0 # Restart counting from the current spike.\n",
    "        else\n",
    "            n_checked += 1\n",
    "        end\n",
    "        k -= 1\n",
    "    end\n",
    "\n",
    "    return SVector(v)\n",
    "end\n",
    "\n",
    "using Test\n",
    "using DelayEmbeddings\n",
    "zt = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
    "xt = [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
    "yt = [1, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
    "Dt = Dataset(xt, yt, zt)\n",
    "\n",
    "# If we encounter two successive spikes, then that is counted as a 0 time interval.\n",
    "expected_m2 = [(0, 1), (1, 1), (2, 1), (0, 2), (0, 0), (1, 0), (0, 1)]\n",
    "expected_m3 = [(0, 2, 1), (0, 0, 2), (1, 0, 2), (0, 1, 0)]\n",
    "expected_m4 = [(0, 0, 2, 1), (1, 0, 2, 1), (0, 1, 0, 2)]\n",
    "@test spikeembed(zt, m = 2) == SVector{2, Int}.(expected_m2)\n",
    "@test spikeembed(zt, m = 3) == SVector{3, Int}.(expected_m3)\n",
    "@test spikeembed(zt, m = 4) == SVector{4, Int}.(expected_m4)\n",
    "\n",
    "# At all time_points\n",
    "@test embed_at_alltimes(Dt; m = 2) == Dataset.([\n",
    "    SVector{2, Int32}.([[0, 1], [1, 1], [0, 1], [1, 1], [2, 1], [3, 1]]),\n",
    "    SVector{2, Int32}.([[2, 0], [0, 2], [1, 2], [0, 1], [1, 1], [2, 1]]),\n",
    "    SVector{2, Int32}.([[1, 1], [2, 1], [0, 2], [0, 0], [1, 0], [0, 1]]),\n",
    "])\n",
    "\n",
    "# At events for specific time series\n",
    "@test embed_at_targetspikes(Dt; m = 2) == Dataset.([\n",
    "    SVector{2, Int32}.([[1, 1], [3, 1]]),\n",
    "    SVector{2, Int32}.([[0, 2], [2, 1]]),\n",
    "    SVector{2, Int32}.([[2, 1], [0, 1]]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = rand([0, 1], 100)\n",
    "# y = rand([0, 1], 100)\n",
    "# z = rand([0, 1], 100)\n",
    "# w = rand([0, 1], 100);\n",
    "# D = Dataset(x, y, z, w);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "450.708 μs (6506 allocations: 343.36 KiB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25.625 μs (655 allocations: 24.06 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Dataset{2, Int64}}:\n",
       " 2-dimensional Dataset{Int64} with 49 points\n",
       " 2-dimensional Dataset{Int64} with 49 points\n",
       " 2-dimensional Dataset{Int64} with 49 points\n",
       " 2-dimensional Dataset{Int64} with 49 points"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 117.083 μs (1887 allocations: 101.22 KiB)\n",
    "# 138.125 μs (2007 allocations: 173.72 KiB)\n",
    "# 160.166 μs (2587 allocations: 219.38 KiB)\n",
    "# 139.208 μs (2199 allocations: 110.89 KiB)\n",
    "# 127.417 μs (1911 allocations: 97.00 KiB)\n",
    "# 24.708 μs (655 allocations: 24.06 KiB)\n",
    "\n",
    "embed_at_targetspikes(D)\n",
    "@btime embed_at_targetspikes($D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  40.500 μs (1176 allocations: 35.94 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Dataset{2, Int64}}:\n",
       " 2-dimensional Dataset{Int64} with 93 points\n",
       " 2-dimensional Dataset{Int64} with 93 points\n",
       " 2-dimensional Dataset{Int64} with 93 points\n",
       " 2-dimensional Dataset{Int64} with 93 points"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_at_alltimes(D)\n",
    "@btime embed_at_alltimes($D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  71.708 μs (1886 allocations: 77.47 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8-dimensional Dataset{Int64} with 49 points, 6-dimensional Dataset{Int64} with 49 points, 8-dimensional Dataset{Int64} with 93 points, 6-dimensional Dataset{Int64} with 93 points)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 430.875 μs (6414 allocations: 579.16 KiB)\n",
    "# 437.625 μs (6942 allocations: 357.48 KiB)\n",
    "# 73.209 μs (1886 allocations: 77.47 KiB)\n",
    "\n",
    "spike_embeddings(D, m = 2)\n",
    "@btime spike_embeddings($D; m = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8-dimensional Dataset{Int64} with 49 points, 6-dimensional Dataset{Int64} with 49 points, 8-dimensional Dataset{Int64} with 93 points, 6-dimensional Dataset{Int64} with 93 points)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a,b,c,d = spike_embeddings(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Dataset{2, Int32}}:\n",
       " 2-dimensional Dataset{Int32} with 6 points\n",
       " 2-dimensional Dataset{Int32} with 6 points\n",
       " 2-dimensional Dataset{Int32} with 6 points"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eᵤ = embed_at_alltimes(D; m = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Dataset{2, Int32}}:\n",
       " 2-dimensional Dataset{Int32} with 2 points\n",
       " 2-dimensional Dataset{Int32} with 2 points\n",
       " 2-dimensional Dataset{Int32} with 2 points"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eₓ = embed_at_targetspikes(D; m = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jₓ, Cₓ, Jᵤ, Cᵤ = spike_embeddings(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6-dimensional Dataset{Int32} with 2 points, 4-dimensional Dataset{Int32} with 2 points, 6-dimensional Dataset{Int32} with 6 points, 4-dimensional Dataset{Int32} with 6 points)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountOccurrences()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "using TransferEntropy\n",
    "function transferentropy_event(e::Entropy, \n",
    "        event::EventIdentifier, \n",
    "        est::ProbabilitiesEstimator,\n",
    "        target::V, source::V, cond::Vararg{V};\n",
    "        m = 2) where V <: AbstractVector\n",
    "    \n",
    "    D = Dataset(target, source, cond...)\n",
    "\n",
    "    # Construct embeddings, given that the events are identified by `event`.\n",
    "    Jₓ, Cₓ, Jᵤ, Cᵤ = spike_embeddings(D, event; m)\n",
    "    return entropy(e, Cₓ, est) +\n",
    "        entropy(e, Jₓ, est) +\n",
    "        entropy(e, Jᵤ, est) -\n",
    "        entropy(e, Cᵤ, est)\n",
    "end\n",
    "\n",
    "transferentropy_event(event::EventIdentifier, est::ProbabilitiesEstimator,\n",
    "    target::V, source::V, cond::Vararg{V};\n",
    "    m = 2, base = 2) where {V <: AbstractVector} = \n",
    "        transferentropy_event(Shannon(; base), event, est, target, source, cond; m)\n",
    "\n",
    "est = CountOccurrences()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  73.375 μs (1773 allocations: 139.50 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.715104009236162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 93.125 μs (1921 allocations: 73.53 KiB)\n",
    "# 77.541 μs (1869 allocations: 99.50 KiB)\n",
    "# 68.875 μs (1833 allocations: 116.69 KiB)\n",
    "using BenchmarkTools\n",
    "transferentropy_event(Shannon(), OneSpike(), est, y, x, z, w, m = 4)\n",
    "@btime te = transferentropy_event(Shannon(), OneSpike(), $est, $y, $x, $z, $w, m = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Couldn't find m=2 spikes in one or more columns of `x`",
     "output_type": "error",
     "traceback": [
      "Couldn't find m=2 spikes in one or more columns of `x`\n",
      "\n",
      "Stacktrace:\n",
      " [1] first_index(x::Dataset{2, Float64}, event::OneSpike; m::Int64)\n",
      "   @ Main ~/Code/Repos/Temp/TransferEntropy.jl/src/knn.ipynb:70\n",
      " [2] embed_at_targetspikes(x::Dataset{2, Float64}, event::OneSpike; m::Int64)\n",
      "   @ Main ~/Code/Repos/Temp/TransferEntropy.jl/src/knn.ipynb:88\n",
      " [3] spike_embeddings(x::Dataset{2, Float64}, event::OneSpike; m::Int64)\n",
      "   @ Main ~/Code/Repos/Temp/TransferEntropy.jl/src/knn.ipynb:112\n",
      " [4] transferentropy_event(::Renyi{Float64, Int64}, ::OneSpike, ::CountOccurrences, ::Vector{Float64}, ::Vector{Float64}; m::Int64)\n",
      "   @ Main ~/Code/Repos/Temp/TransferEntropy.jl/src/knn.ipynb:12\n",
      " [5] top-level scope\n",
      "   @ ~/Code/Repos/Temp/TransferEntropy.jl/src/knn.ipynb:3"
     ]
    }
   ],
   "source": [
    "source = 1e3*rand(Int(1e3));\n",
    "target = 1e3*rand(Int(1e3));\n",
    "transferentropy_event(Shannon(), OneSpike(), CountOccurrences(), target, source, m = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 1e3*rand(Int(1e3));\n",
    "target = 1e3*rand(Int(1e3));\n",
    "sort!(source);\n",
    "sort!(target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Float64}:\n",
       "   0.9380651354707892\n",
       "   1.762270777116215\n",
       "   3.0441187211794896\n",
       "   3.493147575191924\n",
       "   4.527487081727566\n",
       "   5.089478075968379\n",
       "   5.699608150263935\n",
       "   7.256668560836954\n",
       "   8.298347408803973\n",
       "   9.69650134824429\n",
       "   ⋮\n",
       " 990.7641153494266\n",
       " 992.1778901771531\n",
       " 993.2092476329424\n",
       " 993.4613753140692\n",
       " 994.122249662727\n",
       " 994.408453970347\n",
       " 994.6669998126573\n",
       " 995.0014753162362\n",
       " 997.5872382887875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Statistics\n",
    "source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thin_target (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function thin_target(source, target, target_rate)\n",
    "    start_index = 1\n",
    "    while target[start_index] < source[1]\n",
    "         start_index += 1\n",
    "    end\n",
    "    target = target[start_index:end]\n",
    "    new_target = Float64[]\n",
    "    index_of_last_source = 1\n",
    "    for event in target\n",
    "        while index_of_last_source < length(source) && source[index_of_last_source + 1] < event\n",
    "                 index_of_last_source += 1\n",
    "        end\n",
    "        distance_to_last_source = event - source[index_of_last_source]\n",
    "        lambda = 0.5 + 5exp(-50(distance_to_last_source - 0.5)^2) - 5exp(-50(-0.5)^2)\n",
    "        if rand() < lambda/target_rate\n",
    "              push!(new_target, event)\n",
    "        end\n",
    "    end\n",
    "    return new_target\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Could not find m=2 spikes in `x`",
     "output_type": "error",
     "traceback": [
      "Could not find m=2 spikes in `x`\n",
      "\n",
      "Stacktrace:\n",
      " [1] first_index(x::Vector{Float64}, event::OneSpike; m::Int64)\n",
      "   @ Main ~/Code/Repos/Temp/TransferEntropy.jl/src/knn.ipynb:48\n",
      " [2] spikeembed(target::Vector{Float64}, event::OneSpike; m::Int64)\n",
      "   @ Main ~/Code/Repos/Temp/TransferEntropy.jl/src/knn.ipynb:31\n",
      " [3] spikeembed (repeats 2 times)\n",
      "   @ ~/Code/Repos/Temp/TransferEntropy.jl/src/knn.ipynb:22 [inlined]\n",
      " [4] top-level scope\n",
      "   @ ~/Code/Repos/Temp/TransferEntropy.jl/src/knn.ipynb:5"
     ]
    }
   ],
   "source": [
    "source = sort(1e4*rand(Int(1e4)));\n",
    "target = sort(1e4*rand(Int(1e5)));\n",
    "target_thinned = thin_target(source, target, 10)\n",
    "\n",
    "spikeembed(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
