<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Transfer entropy Â· TransferEntropy.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">TransferEntropy.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">TransferEntropy.jl</a></li><li><a class="tocitem" href="../mutualinfo/">Mutual information</a></li><li class="is-active"><a class="tocitem" href>Transfer entropy</a></li><li><a class="tocitem" href="../dataset/">Datasets</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Transfer entropy</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Transfer entropy</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/TransferEntropy.jl/blob/master/docs/src/transferentropy.md" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><article class="docstring"><header><a class="docstring-binding" id="TransferEntropy.transferentropy" href="#TransferEntropy.transferentropy"><code>TransferEntropy.transferentropy</code></a> â€” <span class="docstring-category">Function</span></header><section><div><p><strong>Transfer entropy</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est; base = 2, q = 1, 
    Ï„T = -1, Ï„S = -1, Î·ğ’¯ = 1, dT = 1, dS = 1, dğ’¯ = 1, [Ï„C = -1, dC = 1]) â†’ Float64</code></pre><p>Estimate transfer entropy<sup class="footnote-reference"><a id="citeref-Schreiber2000" href="#footnote-Schreiber2000">[Schreiber2000]</a></sup> from source <code>s</code> to target <code>t</code>, <span>$TE^{q}(s \to t)$</span>, using the  provided entropy/probability estimator <code>est</code> with logarithms to the given <code>base</code>. Optionally, condition  on <code>c</code> and estimate the conditional transfer entropy <span>$TE^{q}(s \to t | c)$</span>. </p><p>Compute either Shannon transfer entropy (<code>q = 1</code>, which is the default) or the order-<code>q</code>  RÃ©nyi transfer entropy<sup class="footnote-reference"><a id="citeref-Jizba2012" href="#footnote-Jizba2012">[Jizba2012]</a></sup> by setting <code>q</code> different from 1.</p><p><strong>Generalized embedding parameters</strong></p><p>Details on how generalized embeddings are constructed from the input time series is  outlined below. In short, the embedding lags <code>Ï„T</code>, <code>Ï„S</code>, <code>Ï„C</code> must be negative, the  prediction lag <code>Î·ğ’¯</code> must be positive, and the embedding dimensions <code>dT</code>, <code>dS</code>, <code>dC</code>, <code>dğ’¯</code>  must be greater than or equal to 1. Thus, the convention is to use negative lags to  indicate embedding delays for past state vectors (for the <span>$T$</span>, <span>$S$</span> and <span>$C$</span> marginals,  detailed below), and positive lags to indicate embedding delays for future state vectors  (for the <span>$\mathcal T$</span> marginal, also detailed below). </p><p>The value(s) of <code>Ï„T</code>, <code>Ï„S</code> or <code>Ï„C</code> affect the estimated <span>$TE$</span> only if the corresponding  dimension(s) <code>dT</code>, <code>dS</code> or <code>dC</code> are larger than <code>1</code>. The default behaviour is to use scalar  time series for each marginal (in that case, the <code>Ï„T</code>, <code>Ï„S</code> or <code>Ï„C</code> does not affect the  analysis).</p><p><strong>Input data</strong></p><p>The input series <code>s</code>, <code>t</code>, and <code>c</code> must be equal-length real-valued vectors.</p><p><strong>Estimation methods</strong></p><p><strong>Binning based</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::VisitationFrequency{RectangularBinning}; base = 2, q = 1, ...) â†’ Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> using visitation frequencies over a rectangular binning.</p><pre><code class="language-none">transferentropy(s, t, [c], est::TransferOperator{RectangularBinning}; base = 2, q = 1, ...) â†’ Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> using an approximation to the transfer operator over rectangular  binning.</p><p>See also: <a href="../#Entropies.VisitationFrequency"><code>VisitationFrequency</code></a>, <a href="../#Entropies.RectangularBinning"><code>RectangularBinning</code></a>.</p><p><strong>Nearest neighbor based</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::Kraskov; base = 2, ...) â†’ Float64
transferentropy(s, t, [c], est::KozachenkoLeonenko; base = 2, ...) â†’ Float64</code></pre><p>Estimate <span>$TE^{1}(s \to t)$</span> or <span>$TE^{1}(s \to t | c)$</span> using naive nearest neighbor estimators.</p><p><em>Note: only Shannon entropy is possible to use for nearest neighbor estimators, so the  keyword <code>q</code> cannot be provided; it is hardcoded as <code>q = 1</code></em>. </p><p>See also <a href="../#Entropies.Kraskov"><code>Kraskov</code></a>, <a href="@ref"><code>KozachenckoLeonenko</code></a>.</p><p><strong>Kernel density based</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::NaiveKernel{Union{TreeDistance, DirectDistance}}; 
    base = 2, q = 1,  ...) â†’ Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> using naive kernel density estimation of  probabilities.</p><p>See also <a href="../#Entropies.NaiveKernel"><code>NaiveKernel</code></a>, <a href="../#Entropies.TreeDistance"><code>TreeDistance</code></a>, <a href="../#Entropies.DirectDistance"><code>DirectDistance</code></a>.</p><p><strong>Instantenous Hilbert amplitudes/phases</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::Hilbert; base = 2, q = 1,  ...) â†’ Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> by first applying the Hilbert transform  to <code>s</code>, <code>t</code> (<code>c</code>) and then estimating transfer entropy.</p><p>See also <a href="../#TransferEntropy.Hilbert"><code>Hilbert</code></a>, <a href="../#TransferEntropy.Amplitude"><code>Amplitude</code></a>, <a href="../#TransferEntropy.Phase"><code>Phase</code></a>.</p><p><strong>Symbolic/permutation</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::SymbolicPermutation; 
    base = 2, q = 1, m::Int = 3, Ï„::Int = 1, ...) â†’ Float64
transferentropy!(symb_s, symb_t, s, t, [c], est::SymbolicPermutation; 
    base = 2, q = 1, m::Int = 3, Ï„::Int = 1, ...) â†’ Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> using permutation entropy. This is done  by first symbolizing the input series <code>s</code> and <code>t</code> (and <code>c</code>; all of length <code>N</code>) using motifs of  size <code>m</code> and a time delay of <code>Ï„</code>. The series of motifs are encoded as integer symbol time  series preserving the permutation information. These symbol time series are embedded as  usual, and transfer entropy is computed from marginal entropies of that generalized embedding.</p><p>Optionally, provide pre-allocated (integer) symbol vectors <code>symb_s</code> and <code>symb_t</code> (and <code>symb_c</code>), where <code>length(symb_s) == length(symb_t) == length(symb_c) == N - (est.m-1)*est.Ï„</code>. This is useful for saving  memory allocations for repeated computations.</p><p>See also <a href="../#Entropies.SymbolicPermutation"><code>SymbolicPermutation</code></a>.</p><p><strong>Description</strong></p><p><strong>Transfer entropy on scalar time series</strong></p><p>Transfer entropy between two simultaneously measured scalar time series <span>$s(n)$</span> and <span>$t(n)$</span>,   <span>$s(n) = \{ s_1, s_2, \ldots, s_N \}$</span> and <span>$t(n) = \{ t_1, t_2, \ldots, t_N \}$</span>, is is defined as </p><p class="math-container">\[TE(s \to t) = \sum_i p(s_i, t_i, t_{i+\eta}) \log \left( \dfrac{p(t_{i+\eta} |Â t_i, s_i)}{p(t_{i+\eta} |Â t_i)} \right)\]</p><p><strong>Transfer entropy on generalized embeddings</strong></p><p>By defining the vector-valued time series, it is possible to include more than one  historical/future value for each marginal (see &#39;Uniform vs. non-uniform embeddings&#39; below for embedding details):</p><ul><li><span>$\mathcal{T}^{(d_{\mathcal T}, \eta_{\mathcal T})} = \{t_i^{(d_{\mathcal T}, \eta_{\mathcal T})} \}_{i=1}^{N}$</span>, </li><li><span>$T^{(d_T, \tau_T)} = \{t_i^{(d_T, \tau_T)} \}_{i=1}^{N}$</span>, </li><li><span>$S^{(d_S, \tau_S)} = \{s_i^{(d_T, \tau_T)} \}_{i=1}^{N}$</span>,  and </li><li><span>$C^{(d_C, \tau_C)} = \{s_i^{(d_C, \tau_C)} \}_{i=1}^{N}$</span>.</li></ul><p>The non-conditioned generalized and conditioned generalized forms of the transfer entropy are then</p><p class="math-container">\[TE(s \to t) = \sum_i p(S,T, \mathcal{T}) \log \left( \dfrac{p(\mathcal{T} |Â T, S)}{p(\mathcal{T} |Â T)} \right)\]</p><p class="math-container">\[TE(s \to t |Â c) = \sum_i p(S,T, \mathcal{T}, C) \log \left( \dfrac{p(\mathcal{T} |Â T, S, C)}{p(\mathcal{T} |Â T, C)} \right)\]</p><p><strong>Uniform vs. non-uniform embeddings</strong></p><p>The <code>N</code> state vectors for each marginal are either </p><ul><li>uniform, of the form <span>$x_{i}^{(d, \omega)} = (x_i, x_{i+\omega}, x_{i+2\omega}, \ldots x_{i+(d - 1)\omega})$</span>,    with equally spaced state vector entries. <em>Note: When constructing marginals for <span>$T$</span>, <span>$S$</span> and <span>$C$</span>,    we need <span>$\omega \leq 0$</span> to get present/past values, while <span>$\omega &gt; 0$</span> is necessary to get future states    when constructing <span>$\mathcal{T}$</span>.</em></li><li>non-uniform, of the form <span>$x_{i}^{(d, \omega)} = (x_i, x_{i+\omega_1}, x_{i+\omega_2}, \ldots x_{i+\omega_{d}})$</span>,   with non-equally spaced state vector entries <span>$\omega_1, \omega_2, \ldots, \omega_{d}$</span>,   which can be freely chosen. <em>Note: When constructing marginals for <span>$T$</span>, <span>$S$</span> and <span>$C$</span>,    we need <span>$\omega_i \leq 0$</span> for all <span>$\omega_i$</span> to get present/past values, while <span>$\omega_i &gt; 0$</span> for all <span>$\omega_i$</span>    is necessary to get future states when constructing <span>$\mathcal{T}$</span>.</em></li></ul><p>In practice, the <code>dT</code>-dimensional, <code>d_S</code>-dimensional and <code>d_C</code>-dimensional state vectors  comprising <span>$T$</span>, <span>$S$</span> and <span>$C$</span> are constructed with embedding lags <code>Ï„T</code>,  <code>Ï„S</code>, and <code>Ï„C</code>, respectively. The <code>dğ’¯</code>-dimensional future states <span>$\mathcal{T}^{(d_{\mathcal T}, \eta_{\mathcal T})}$</span> are constructed with prediction lag <code>Î·ğ’¯</code> (i.e. predictions go from present/past states to  future states spanning a maximum of <code>dğ’¯*Î·ğ’¯</code> time steps). <em>Note: in Schreiber&#39;s paper, only the historical states are defined as  potentially higher-dimensional, while the future states are always scalar.</em></p><p><strong>Estimation</strong></p><p>Transfer entropy is here estimated by rewriting the above expressions as a sum of marginal  entropies, and extending the definitions above to use RÃ©nyi generalized entropies of order  <code>q</code> as</p><p class="math-container">\[TE^{q}(s \to t) = H^{q}(\mathcal T, T) + H^{q}(T, S) - H^{q}(T) - H^{q}(\mathcal T, T, S),\]</p><p class="math-container">\[TE^{q}(s \to t | c) = H^{q}(\mathcal T, T, C) + H^{q}(T, S, C) - H^{q}(T, C) - H^{q}(\mathcal T, T, S, C),\]</p><p>where <span>$H^{q}(\cdot)$</span> is the generalized RÃ©nyi entropy of order <span>$q$</span>. This is equivalent to the RÃ©nyi transfer entropy implementation in Jizba et al. (2012)<sup class="footnote-reference"><a id="citeref-Jizba2012" href="#footnote-Jizba2012">[Jizba2012]</a></sup>.</p><p><strong>Examples</strong></p><p>Default estimation (scalar marginals): </p><pre><code class="language-julia"># Symbolic estimator, motifs of length 4, uniform delay vectors with lag 1
est = SymbolicPermutation(m = 4, Ï„ = 1) 

x, y = rand(100), rand(100)
transferentropy(x, y, est)</code></pre><p>Increasing the dimensionality of the <span>$T$</span> marginal (present/past states of the target  variable):</p><pre><code class="language-julia"># Binning-based estimator
est = VisitationFrequency(RectangularBinning(4)) 
x, y = rand(100), rand(100)

# Uniform delay vectors when `Ï„T` is an integer (see explanation above)
# Here t_{i}^{(dT, Ï„T)} = (t_i, t_{i+Ï„}, t_{i+2Ï„}, \ldots t_{i+(dT-1)Ï„})
# = (t_i, t_{i-2}, t_{i-4}, \ldots t_{i-6Ï„}), so we need zero/negative values for `Ï„T`.
transferentropy(x, y, est, dT = 4, Ï„T = -2)

# Non-uniform delay vectors when `Ï„T` is a vector of integers
# Here t_{i}^{(dT, Ï„T)} = (t_i, t_{i+Ï„_{1}}, t_{i+Ï„_{2}}, \ldots t_{i+Ï„_{dT}})
# = (t_i, t_{i-7}, t_{i-25}), so we need zero/negative values for `Ï„T`.
transferentropy(x, y, est, dT = 3, Ï„T = [0, -7, -25])</code></pre><p>Logarithm bases and the order of the RÃ©nyi entropy can also be tuned:</p><pre><code class="language-julia">x, y = rand(100), rand(100)
est = NaiveKernel(0.3)
transferentropy(x, y, est, base = MathConstants.e, q = 2) # TE in nats, order-2 RÃ©nyi entropy</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/TransferEntropy.jl/blob/3ce62f699a18a7997cbc4e0549e96fd5344a0fe8/src/transferentropy/interface.jl#L47-L257">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Schreiber2000"><a class="tag is-link" href="#citeref-Schreiber2000">Schreiber2000</a>Schreiber, T. (2000). Measuring information transfer. Physical review letters, 85(2), 461.</li><li class="footnote" id="footnote-Jizba2012"><a class="tag is-link" href="#citeref-Jizba2012">Jizba2012</a>Jizba, P., Kleinert, H., &amp; Shefaat, M. (2012). RÃ©nyiâ€™s information transfer between financial time series. Physica A: Statistical Mechanics and its Applications, 391(10), 2971-2989.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../mutualinfo/">Â« Mutual information</a><a class="docs-footer-nextpage" href="../dataset/">Datasets Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 7 April 2021 21:46">Wednesday 7 April 2021</span>. Using Julia version 1.6.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
