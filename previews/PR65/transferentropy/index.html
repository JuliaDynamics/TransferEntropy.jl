<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Transfer entropy ¬∑ TransferEntropy.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">TransferEntropy.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">TransferEntropy.jl</a></li><li><a class="tocitem" href="../mutualinfo/">Mutual information</a></li><li class="is-active"><a class="tocitem" href>Transfer entropy</a></li><li><a class="tocitem" href="../dataset/">Datasets</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Transfer entropy</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Transfer entropy</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/TransferEntropy.jl/blob/master/docs/src/transferentropy.md" title="Edit on GitHub"><span class="docs-icon fab">ÔÇõ</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><article class="docstring"><header><a class="docstring-binding" id="TransferEntropy.transferentropy" href="#TransferEntropy.transferentropy"><code>TransferEntropy.transferentropy</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><p><strong>Transfer entropy (general interface)</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est; base = 2, q = 1, 
    œÑT = -1, œÑS = -1, Œ∑ùíØ = 1, dT = 1, dS = 1, dùíØ = 1, [œÑC = -1, dC = 1]) ‚Üí Float64</code></pre><p>Estimate transfer entropy from source <code>s</code> to target <code>t</code>, <span>$TE^{q}(s \to t)$</span>, using the  provided entropy/probability estimator <code>est</code> and R√©nyi entropy of order-<code>q</code> (defaults to <code>q = 1</code>,  which is the Shannon entropy), with logarithms to the given <code>base</code>. Optionally, condition  on <code>c</code> and estimate the conditional transfer entropy <span>$TE^{q}(s \to t | c)$</span>. </p><p>Parameters for embedding lags <code>œÑT</code>, <code>œÑS</code>, <code>œÑC</code> (must be negative), the prediction lag <code>Œ∑ùíØ</code>  (must be positive), and the embedding dimensions <code>dT</code>, <code>dS</code>, <code>dC</code>, <code>dùíØ</code> have meanings as  explained above. Here, the convention is to use negative lags to indicate embedding delays  for past state vectors (for the <span>$T$</span>, <span>$S$</span> and <span>$C$</span> marginals), and positive lags to  indicate embedding delays for future state vectors (for the <span>$\mathcal T$</span> marginal). </p><p>Default embedding values use scalar time series for each marginal. Hence, the value(s) of  <code>œÑT</code>, <code>œÑS</code> or <code>œÑC</code> affect the estimated <span>$TE$</span> only if the corresponding dimension(s)  <code>dT</code>, <code>dS</code> or <code>dC</code> are larger than <code>1</code>.</p><p>The input series <code>s</code>, <code>t</code>, and <code>c</code> must be equal-length real-valued vectors of length <code>N</code>.</p><p><strong>Binning based</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::VisitationFrequency{RectangularBinning}; base = 2, q = 1, ...) ‚Üí Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> using visitation frequencies over a rectangular binning.</p><pre><code class="language-none">transferentropy(s, t, [c], est::TransferOperator{RectangularBinning}; base = 2, q = 1, ...) ‚Üí Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> using an approximation to the transfer operator over rectangular  binning.</p><p>See also: <a href="../#Entropies.VisitationFrequency"><code>VisitationFrequency</code></a>, <a href="../#Entropies.RectangularBinning"><code>RectangularBinning</code></a>.</p><p><strong>Nearest neighbor based</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::Kraskov; base = 2, ...) ‚Üí Float64
transferentropy(s, t, [c], est::KozachenkoLeonenko; base = 2, ...) ‚Üí Float64</code></pre><p>Estimate <span>$TE^{1}(s \to t)$</span> or <span>$TE^{1}(s \to t | c)$</span> using naive nearest neighbor estimators.</p><p><em>Note: only Shannon entropy is possible to use for nearest neighbor estimators, so the  keyword <code>q</code> cannot be provided; it is hardcoded as <code>q = 1</code></em>. </p><p>See also <a href="../#Entropies.Kraskov"><code>Kraskov</code></a>, <a href="@ref"><code>KozachenckoLeonenko</code></a>.</p><p><strong>Kernel density based</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::NaiveKernel{Union{TreeDistance, DirectDistance}}; 
    base = 2, q = 1,  ...) ‚Üí Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> using naive kernel density estimation of  probabilities.</p><p>See also <a href="../#Entropies.NaiveKernel"><code>NaiveKernel</code></a>, <a href="../#Entropies.TreeDistance"><code>TreeDistance</code></a>, <a href="../#Entropies.DirectDistance"><code>DirectDistance</code></a>.</p><p><strong>Instantenous Hilbert amplitudes/phases</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::Hilbert; base = 2, q = 1,  ...) ‚Üí Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> by first applying the Hilbert transform  to <code>s</code>, <code>t</code> (<code>c</code>) and then estimating transfer entropy.</p><p>See also <a href="../#TransferEntropy.Hilbert"><code>Hilbert</code></a>, <a href="../#TransferEntropy.Amplitude"><code>Amplitude</code></a>, <a href="../#TransferEntropy.Phase"><code>Phase</code></a>.</p><p><strong>Symbolic/permutation</strong></p><pre><code class="language-none">transferentropy(s, t, [c], est::SymbolicPermutation; 
    base = 2, q = 1, m::Int = 3, œÑ::Int = 1, ...) ‚Üí Float64
transferentropy!(symb_s, symb_t, s, t, [c], est::SymbolicPermutation; 
    base = 2, q = 1, m::Int = 3, œÑ::Int = 1, ...) ‚Üí Float64</code></pre><p>Estimate <span>$TE^{q}(s \to t)$</span> or <span>$TE^{q}(s \to t | c)$</span> using permutation entropy. This is done  by first symbolizing the input series <code>s</code> and <code>t</code> (and <code>c</code>; all of length <code>N</code>) using motifs of  size <code>m</code> and a time delay of <code>œÑ</code>. The series of motifs are encoded as integer symbol time  series preserving the permutation information. These symbol time series are embedded as  usual, and transfer entropy is computed from marginal entropies of that generalized embedding.</p><p>Optionally, provide pre-allocated (integer) symbol vectors <code>symb_s</code> and <code>symb_t</code> (and <code>symb_c</code>), where <code>length(symb_s) == length(symb_t) == length(symb_c) == N - (est.m-1)*est.œÑ</code>. This is useful for saving  memory allocations for repeated computations.</p><p>See also <a href="../#Entropies.SymbolicPermutation"><code>SymbolicPermutation</code></a>.</p><p><strong>Description</strong></p><p><strong>Transfer entropy on scalar time series</strong></p><p>Transfer entropy between two simultaneously measured scalar time series <span>$s(n)$</span> and <span>$t(n)$</span>,   <span>$s(n) = \{ s_1, s_2, \ldots, s_N \}$</span> and <span>$t(n) = \{ t_1, t_2, \ldots, t_N \}$</span>, is is defined as </p><p class="math-container">\[TE(s \to t) = \sum_i p(s_i, t_i, t_{i+\eta}) \log \left( \dfrac{p(t_{i+\eta} |¬†t_i, s_i)}{p(t_{i+\eta} |¬†t_i)} \right)\]</p><p><strong>Transfer entropy on generalized embeddings</strong></p><p>By defining the vector-valued time series, it is possible to include more than one  historical/future value for each marginal (see &#39; Uniform vs. non-uniform embeddings&#39; below for embedding details):</p><ul><li><span>$\mathcal{T}^{(d_{\mathcal T}, \eta_{\mathcal T})} = \{t_i^{(d_{\mathcal T}, \eta_{\mathcal T})} \}_{i=1}^{N}$</span>, </li><li><span>$T^{(d_T, \tau_T)} = \{t_i^{(d_T, \tau_T)} \}_{i=1}^{N}$</span>, </li><li><span>$S^{(d_S, \tau_S)} = \{s_i^{(d_T, \tau_T)} \}_{i=1}^{N}$</span>,  and </li><li><span>$C^{(d_C, \tau_C)} = \{s_i^{(d_C, \tau_C)} \}_{i=1}^{N}$</span>.</li></ul><p>The non-conditioned generalized and conditioned generalized forms of the transfer entropy are then</p><p class="math-container">\[TE(s \to t) = \sum_i p(S,T, \mathcal{T}) \log \left( \dfrac{p(\mathcal{T} |¬†T, S)}{p(\mathcal{T} |¬†T)} \right)\]</p><p class="math-container">\[TE(s \to t |¬†c) = \sum_i p(S,T, \mathcal{T}, C) \log \left( \dfrac{p(\mathcal{T} |¬†T, S, C)}{p(\mathcal{T} |¬†T, C)} \right)\]</p><p><strong>Uniform vs. non-uniform embeddings</strong></p><p>The <code>N</code> state vectors for each marginal are either </p><ul><li>uniform, of the form <span>$x_{i}^{(d, \omega_X)} = (x_i, x_{i+\omega}, x_{i+2\omega}, \ldots x_{i+(d - 1)\omega})$</span>,    with equally spaced state vector entries. *Remember: When constructing marginals for <span>$T$</span>, <span>$S$</span> and <span>$C$</span>,    we need <span>$\omega \leq 0$</span> to get present/past values, while <span>$\omega &gt; 0$</span> is necessary to get future states    when constructing <span>$\mathcal{T}$</span>.</li><li>non-uniform, of the form <span>$x_{i}^{(d, \omega)} = (x_i, x_{i+\omega_1}, x_{i+\omega_2}, \ldots x_{i+\omega_{d}})$</span>,   with non-equally spaced state vector entries <span>$\omega_1, \omega_2, \ldots, \omega_{d}$</span>,   which can be freely chosen. <em>Remember: When constructing marginals for <span>$T$</span>, <span>$S$</span> and <span>$C$</span>,    we need <span>$\omega_i \leq 0$</span> for all <span>$\omega_i$</span> to get present/past values, while <span>$\omega_i &gt; 0$</span> for all <span>$\omega_i$</span>    is necessary to get future states when constructing <span>$\mathcal{T}$</span>.</em></li></ul><p>In summary, The <span>$d_T$</span>-dimensional, <span>$d_S$</span>-dimensional and <span>$d_C$</span>-dimensional state vectors  comprising <span>$T$</span>, <span>$S$</span> and <span>$C$</span> are constructed with embedding lags <span>$\tau_T$</span>,  <span>$\tau_S$</span>, and <span>$\tau_C$</span>, respectively. The <span>$d_{\mathcal T}$</span>-dimensional  future states <span>$\mathcal{T}^{(d_{\mathcal T}, \eta_{\mathcal T})}$</span> are constructed with prediction lag <span>$\eta_{\mathcal T}$</span> (i.e. predictions go from  present/past states to future states spanning a maximum of  <span>$d_{\mathcal T} \eta_{\mathcal T}$</span> time steps). <em>Note: in Schreiber&#39;s paper, only the historical states are defined as  potentially higher-dimensional, while the future states are always scalar.</em></p><p><strong>Estimation</strong></p><p>Transfer entropy is here estimated by rewriting the above expressions as a sum of marginal  entropies, and extending the definitions above to use R√©nyi generalized entropies of order  <code>q</code> as</p><p class="math-container">\[TE^{q}(s \to t) = H^{q}(\mathcal T, T) + H^{q}(T, S) - H^{q}(T) - H^{q}(\mathcal T, T, S),\]</p><p class="math-container">\[TE^{q}(s \to t | c) = H^{q}(\mathcal T, T, C) + H^{q}(T, S, C) - H^{q}(T, C) - H^{q}(\mathcal T, T, S, C),\]</p><p>where <span>$H^{q}(\cdot)$</span> is the generalized Renyi entropy of order <span>$q$</span>. </p><p><strong>Examples</strong></p><p>Default estimation (scalar marginals): </p><pre><code class="language-julia"># Symbolic estimator, motifs of length 4, uniform delay vectors with lag 1
est = SymbolicPermutation(m = 4, œÑ = 1) 

x, y = rand(100), rand(100)
transferentropy(x, y, est)</code></pre><p>Increasing the dimensionality of the <span>$T$</span> marginal (present/past states of the target  variable):</p><pre><code class="language-julia"># Binning-based estimator
est = VisitationFrequency(RectangularBinning(4)) 
x, y = rand(100), rand(100)

# Uniform delay vectors when `œÑT` is an integer (see explanation above)
# Here t_{i}^{(dT, œÑT)} = (t_i, t_{i+œÑ}, t_{i+2œÑ}, \ldots t_{i+(dT-1)œÑ})
# = (t_i, t_{i-2}, t_{i-4}, \ldots t_{i-6œÑ}), so we need zero/negative values for `œÑT`.
transferentropy(x, y, est, dT = 4, œÑT = -2)

# Non-uniform delay vectors when `œÑT` is a vector of integers
# Here t_{i}^{(dT, œÑT)} = (t_i, t_{i+œÑ_{1}}, t_{i+œÑ_{2}}, \ldots t_{i+œÑ_{dT}})
# = (t_i, t_{i-7}, t_{i-25}), so we need zero/negative values for `œÑT`.
transferentropy(x, y, est, dT = 3, œÑT = [0, -7, -25])</code></pre><p>Logarithm bases and the order of the R√©nyi entropy can also be tuned:</p><pre><code class="language-julia">x, y = rand(100), rand(100)
est = NaiveKernel(0.3)
transferentropy(x, y, est, base = MathConstants.e, q = 2) # TE in nats, order-2 R√©nyi entropy</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/TransferEntropy.jl/blob/f96ac32da3837d7b1b6736ba010e82e2a627918f/src/transferentropy/interface.jl#L47-L245">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../mutualinfo/">¬´ Mutual information</a><a class="docs-footer-nextpage" href="../dataset/">Datasets ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 7 April 2021 16:51">Wednesday 7 April 2021</span>. Using Julia version 1.6.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
